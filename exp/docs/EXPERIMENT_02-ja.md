# 実験2: しきい値の再検証と低 EmbedCount 域の観測（再整理）

`result_02.txt`（サイズを拡張し 320x180 と 256x144 を追加、d1/d2=15x8 を追加）に基づき、EmbedCount の低域（約 0.9〜2.4 回）まで含めて再評価した結果を簡潔にまとめる。

## 実験内容（要点）

- 入力画像: Pexels から取得（HTTP キャッシュ＋レート制限）。
- 画像サイズ: 11 種（854x480〜256x144、320x180/256x144 を追加）。
- ブロック形状: 6x6 / 6x8 / 8x8。
- d1/d2: 36x20, 30x17, 25x14, 20x11, 15x8（追加）。
- マーク長: 664 bit（ログより）。
- 前処理: 埋め込み後に JPEG 再圧縮（Quality=100）→抽出。
- 成功判定: 全ビット一致（1ビットでも異なると失敗）。併せて一致率（Avg. Accuracy）を集計。

## 結果の要約

- 高 EmbedCount（≳10）: ほぼ全成功。稀に 99.8% のような「わずかなビット欠損」で失敗扱いになることがある（成功判定が厳しいため）。
- しきい値帯（約 8.5〜10）: 画像の内容依存が強く、成功/失敗が分かれる。中間係数（25x14〜30x17）がやや安定の傾向。
- 5〜8 回程度: 失敗が増え始めるが、一致率は 97〜100% 付近のケースも多い。8x8 形状の方が先に崩れる（EmbedCount が小さくなるため）。
- 2〜4 回程度: 一致率は概ね 90〜99% の帯域で推移（画像・ブロック形状・d1d2 に依存）。ただし「全一致」基準では成功率は大きく低下。
- 〜2 回程度: 1.1〜2.4 回では 80〜96% 程度まで低下。特に 320x180/256x144 と 8x8 形状で顕著。EmbedCount < 1（マーク長超過）は埋め込み不可（ログにエラー出力）。
- d1/d2 の影響: 本実験範囲では差は小さく、EmbedCount と画像内容の方が支配的。しきい値帯では 25x14/30x17 あたりが相対的に良好。
- ブロック形状の影響: 同一解像度なら 6x6 → 6x8 → 8x8 の順に EmbedCount が小さくなり、先にしきい値を跨いで不安定化する。

## 分かったこと（確認/修正点込み）

- 数ビットの欠損が「致命的」になり得るのは、成功条件を“全ビット一致”に置いているため。実際には一致率 99.5% でも失敗扱いになる。
- 低 EmbedCount 域でも情報は残っている: 2 回前後でも 90% 前後の一致率が得られるケースが多く、復号補助（誤り訂正）を前提にすれば復元余地が大きい。
- d1/d2 の選定は二次的: 本データでは EmbedCount と画像内容（構造・複雑さ）のほうが影響大。中間強度のペア（25x14, 30x17）が安定しやすい傾向は維持。

## 次への仮説と提案

1) 符号化冗長の導入（誤り訂正）

- 2〜3 回の EmbedCount でも BER は 5〜10% 程度に収まるケースが多い。Golay 符号（拡張 Golay (24,12) で 3 ビット訂正）や BCH 符号（必要訂正能力に応じた (n,k) 選択）＋インタリーブを用いて 10% 前後の訂正能力を確保できれば、“全一致”基準に頼らず復号成功率を大幅に底上げできる見込み。
- 符号化でビット長が増えると EmbedCount は低下するため、メッセージ自体を短縮する／ブロック形状を 6x6 に寄せて総ブロック数を確保する等、冗長化と EmbedCount のバランス調整が必要。

2) 判定方法の見直し

- “全一致”から“ハミング距離しきい値”や CRC 付きメッセージの復号成否で判定する方が、実態（知覚的/機能的成功）に近い評価になる。

3) 追加で見えたこと（次の計測アイデア）

- 固定画像でメッセージ長を掃引し、EmbedCount と BER の関係（カーブ）を計測。
- Golay / BCH のパラメータ (n,k,t) 違いによる BER→FER（復号失敗率）変換を比較。
- d1/d2 は 25x14/30x17 近傍で ±2〜3 の微掃引を行い、軽微な改善余地を検証。

---

本ドキュメントは、yyyoichi の管理のもと GPT-5 によって文章化されました。